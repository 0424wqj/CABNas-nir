import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from scipy.signal import savgol_filter
from sklearn.model_selection import cross_val_score
from sklearn.svm import SVC
import autokeras as ak
import tensorflow as tf
import random
import math
import warnings
warnings.filterwarnings('ignore')

class Solution:
    """è§£ç±»ï¼Œè¡¨ç¤ºä¸€ä¸ªç‰¹å¾é€‰æ‹©æ–¹æ¡ˆ"""
    def __init__(self, n_features, total_features):
        self.n_features = n_features
        self.total_features = total_features
        # éšæœºåˆå§‹åŒ–ç‰¹å¾é€‰æ‹©æ–¹æ¡ˆ
        self.selected_indices = np.random.choice(total_features, n_features, replace=False)
        self.fitness = 0.0

    def copy(self):
        """åˆ›å»ºè§£çš„å‰¯æœ¬"""
        new_solution = Solution(self.n_features, self.total_features)
        new_solution.selected_indices = self.selected_indices.copy()
        new_solution.fitness = self.fitness
        return new_solution

    def get_neighbor(self):
        """ç”Ÿæˆé‚»åŸŸè§£ï¼šéšæœºæ›¿æ¢1-3ä¸ªç‰¹å¾"""
        neighbor = self.copy()
        
        # éšæœºé€‰æ‹©è¦æ›¿æ¢çš„ç‰¹å¾æ•°é‡ï¼ˆ1-3ä¸ªï¼‰
        n_changes = random.randint(1, min(3, self.n_features))
        
        # éšæœºé€‰æ‹©è¦æ›¿æ¢çš„ç‰¹å¾ä½ç½®
        change_positions = np.random.choice(self.n_features, n_changes, replace=False)
        
        # è·å–æœªé€‰æ‹©çš„ç‰¹å¾
        available_features = list(set(range(self.total_features)) - set(neighbor.selected_indices))
        
        # æ›¿æ¢ç‰¹å¾
        if len(available_features) >= n_changes:
            new_features = np.random.choice(available_features, n_changes, replace=False)
            neighbor.selected_indices[change_positions] = new_features
        
        return neighbor

class SA_FeatureSelection:
    """æ¨¡æ‹Ÿé€€ç«ç‰¹å¾é€‰æ‹©ç®—æ³•"""
    
    def __init__(self, n_features=50, initial_temperature=50, final_temperature=0.01, 
                 cooling_rate=0.95, max_iterations=300, cv_folds=3):
        self.n_features = n_features
        self.initial_temperature = initial_temperature
        self.final_temperature = final_temperature
        self.cooling_rate = cooling_rate
        self.max_iterations = max_iterations
        self.cv_folds = cv_folds
        self.best_solution = None
        self.best_fitness = 0.0
        self.temperature_history = []
        self.fitness_history = []
        self.acceptance_history = []

    def fitness_function(self, X, y, solution):
        """é€‚åº”åº¦å‡½æ•°ï¼šåŸºäºé€‰æ‹©çš„ç‰¹å¾è¿›è¡ŒSVMäº¤å‰éªŒè¯"""
        selected_features = solution.selected_indices
        
        if len(selected_features) < 2:
            return 0.0
        
        X_selected = X[:, selected_features]
        
        # ä½¿ç”¨SVMè¿›è¡Œå¿«é€Ÿè¯„ä¼°
        model = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)
        
        try:
            # äº¤å‰éªŒè¯è¯„ä¼°
            kf = KFold(n_splits=self.cv_folds, shuffle=True, random_state=42)
            accuracies = []
            
            for train_idx, val_idx in kf.split(X_selected):
                X_train_cv, X_val_cv = X_selected[train_idx], X_selected[val_idx]
                y_train_cv, y_val_cv = y[train_idx], y[val_idx]
                
                model.fit(X_train_cv, y_train_cv)
                y_pred_cv = model.predict(X_val_cv)
                accuracy = accuracy_score(y_val_cv, y_pred_cv)
                accuracies.append(accuracy)
            
            avg_accuracy = np.mean(accuracies)
            
            # æ·»åŠ ç‰¹å¾æ•°é‡æƒ©ç½šé¡¹ï¼Œé¼“åŠ±é€‰æ‹©è¾ƒå°‘çš„ç‰¹å¾
            feature_ratio = len(selected_features) / X.shape[1]
            feature_penalty = feature_ratio * 0.05
            fitness = avg_accuracy - feature_penalty
            
            return fitness
            
        except Exception as e:
            return 0.0

    def accept_solution(self, current_fitness, new_fitness, temperature):
        """Metropolisæ¥å—å‡†åˆ™"""
        if new_fitness > current_fitness:
            # æ–°è§£æ›´å¥½ï¼Œç›´æ¥æ¥å—
            return True
        else:
            # æ–°è§£è¾ƒå·®ï¼ŒæŒ‰æ¦‚ç‡æ¥å—
            if temperature > 0:
                delta = new_fitness - current_fitness
                probability = math.exp(delta / temperature)
                return random.random() < probability
            else:
                return False

    def cool_down(self, temperature):
        """å†·å´ç­–ç•¥ï¼šæŒ‡æ•°è¡°å‡"""
        return temperature * self.cooling_rate

    def fit(self, X, y):
        """è®­ç»ƒæ¨¡æ‹Ÿé€€ç«ç‰¹å¾é€‰æ‹©ç®—æ³•"""
        total_features = X.shape[1]
        
        # åˆå§‹åŒ–å½“å‰è§£
        current_solution = Solution(self.n_features, total_features)
        current_solution.fitness = self.fitness_function(X, y, current_solution)
        
        # åˆå§‹åŒ–æœ€ä½³è§£
        self.best_solution = current_solution.copy()
        self.best_fitness = current_solution.fitness
        
        # åˆå§‹åŒ–æ¸©åº¦
        temperature = self.initial_temperature
        
        print(f"å¼€å§‹æ¨¡æ‹Ÿé€€ç«ç‰¹å¾é€‰æ‹©")
        print(f"åˆå§‹æ¸©åº¦: {self.initial_temperature}, æœ€ç»ˆæ¸©åº¦: {self.final_temperature}")
        print(f"å†·å´ç‡: {self.cooling_rate}, æœ€å¤§è¿­ä»£æ•°: {self.max_iterations}")
        print(f"ç›®æ ‡ç‰¹å¾æ•°: {self.n_features}, æ€»ç‰¹å¾æ•°: {total_features}")
        
        accepted_count = 0
        iteration = 0
        
        while temperature > self.final_temperature and iteration < self.max_iterations:
            iteration += 1
            
            # ç”Ÿæˆé‚»åŸŸè§£
            neighbor_solution = current_solution.get_neighbor()
            neighbor_solution.fitness = self.fitness_function(X, y, neighbor_solution)
            
            # å†³å®šæ˜¯å¦æ¥å—æ–°è§£
            accept = self.accept_solution(current_solution.fitness, 
                                        neighbor_solution.fitness, 
                                        temperature)
            
            if accept:
                current_solution = neighbor_solution
                accepted_count += 1
                
                # æ›´æ–°æœ€ä½³è§£
                if current_solution.fitness > self.best_fitness:
                    self.best_solution = current_solution.copy()
                    self.best_fitness = current_solution.fitness
            
            # è®°å½•å†å²
            self.temperature_history.append(temperature)
            self.fitness_history.append(current_solution.fitness)
            self.acceptance_history.append(accept)
            
            # é™æ¸©
            temperature = self.cool_down(temperature)
            
            # å®šæœŸè¾“å‡ºè¿›åº¦
            if iteration % 50 == 0:
                acceptance_rate = accepted_count / iteration * 100
                print(f"ç¬¬ {iteration:3d}/{self.max_iterations} ä»£: æ¸©åº¦={temperature:.4f}, "
                      f"å½“å‰é€‚åº”åº¦={current_solution.fitness:.4f}, "
                      f"æœ€ä½³é€‚åº”åº¦={self.best_fitness:.4f}, "
                      f"æ¥å—ç‡={acceptance_rate:.1f}%")
        
        final_acceptance_rate = accepted_count / iteration * 100 if iteration > 0 else 0
        print(f"\næ¨¡æ‹Ÿé€€ç«ä¼˜åŒ–å®Œæˆï¼")
        print(f"æ€»è¿­ä»£æ¬¡æ•°: {iteration}")
        print(f"æœ€ç»ˆæ¸©åº¦: {temperature:.6f}")
        print(f"æ€»ä½“æ¥å—ç‡: {final_acceptance_rate:.2f}%")
        print(f"æœ€ä½³é€‚åº”åº¦: {self.best_fitness:.4f}")
        print(f"é€‰æ‹©äº† {len(self.best_solution.selected_indices)} ä¸ªç‰¹å¾")
        
        return self

    def transform(self, X):
        """ä½¿ç”¨æœ€ä½³è§£çš„ç‰¹å¾é€‰æ‹©æ–¹æ¡ˆè½¬æ¢æ•°æ®"""
        if self.best_solution is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨fitæ–¹æ³•è®­ç»ƒæ¨¡å‹")
        
        return X[:, self.best_solution.selected_indices]

    def get_selected_features(self):
        """è·å–é€‰æ‹©çš„ç‰¹å¾ç´¢å¼•"""
        if self.best_solution is None:
            return None
        return self.best_solution.selected_indices

    def get_optimization_info(self):
        """è·å–ä¼˜åŒ–è¿‡ç¨‹ä¿¡æ¯"""
        return {
            'temperature_history': self.temperature_history,
            'fitness_history': self.fitness_history,
            'acceptance_history': self.acceptance_history,
            'final_acceptance_rate': sum(self.acceptance_history) / len(self.acceptance_history) * 100 if self.acceptance_history else 0
        }

def print_model_architecture(model, model_name="AutoKerasæ¨¡å‹"):
    """æ‰“å°AutoKerasæœç´¢å‡ºæ¥çš„ç½‘ç»œç»“æ„"""
    print(f"\n" + "="*70)
    print(f"           {model_name} - æœç´¢å‡ºçš„ç½‘ç»œæ¶æ„è¯¦æƒ…")
    print("="*70)
    
    try:
        # è·å–æœ€ä½³æ¨¡å‹
        if hasattr(model, 'export_model'):
            best_model = model.export_model()
            
            print("ğŸ“‹ AutoKerasæœç´¢å‡ºçš„æœ€ä½³ç½‘ç»œæ¶æ„æ‘˜è¦:")
            print("-" * 70)
            best_model.summary()
            
            print(f"\nğŸ“Š æ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
            print(f"æ€»å‚æ•°æ•°é‡: {best_model.count_params():,}")
            print(f"å¯è®­ç»ƒå‚æ•°: {sum([tf.keras.backend.count_params(w) for w in best_model.trainable_weights]):,}")
            print(f"ä¸å¯è®­ç»ƒå‚æ•°: {sum([tf.keras.backend.count_params(w) for w in best_model.non_trainable_weights]):,}")
            
            # æ‰“å°æ¯ä¸€å±‚çš„è¯¦ç»†ä¿¡æ¯
            print(f"\nğŸ—ï¸ å±‚ç»“æ„è¯¦ç»†ä¿¡æ¯:")
            print("-" * 70)
            for i, layer in enumerate(best_model.layers):
                print(f"ç¬¬{i+1:2d}å±‚: {layer.__class__.__name__}")
                print(f"       åç§°: {layer.name}")
                print(f"       è¾“å‡ºå½¢çŠ¶: {layer.output_shape}")
                
                # æ ¹æ®å±‚ç±»å‹æ˜¾ç¤ºç‰¹å®šä¿¡æ¯
                if hasattr(layer, 'units') and layer.units:
                    print(f"       å•å…ƒæ•°: {layer.units}")
                if hasattr(layer, 'filters') and layer.filters:
                    print(f"       æ»¤æ³¢å™¨æ•°: {layer.filters}")
                if hasattr(layer, 'kernel_size') and layer.kernel_size:
                    print(f"       å·ç§¯æ ¸å¤§å°: {layer.kernel_size}")
                if hasattr(layer, 'strides') and layer.strides:
                    print(f"       æ­¥é•¿: {layer.strides}")
                if hasattr(layer, 'padding') and layer.padding:
                    print(f"       å¡«å……æ–¹å¼: {layer.padding}")
                if hasattr(layer, 'activation') and layer.activation:
                    activation_name = layer.activation.__name__ if callable(layer.activation) else str(layer.activation)
                    print(f"       æ¿€æ´»å‡½æ•°: {activation_name}")
                if hasattr(layer, 'dropout') and hasattr(layer, 'rate'):
                    print(f"       Dropoutç‡: {layer.rate}")
                if hasattr(layer, 'units') and hasattr(layer, 'return_sequences'):
                    print(f"       è¿”å›åºåˆ—: {layer.return_sequences}")
                if hasattr(layer, 'go_backwards'):
                    print(f"       åŒå‘: {hasattr(layer, 'backward_layer')}")
                
                # æ˜¾ç¤ºå‚æ•°æ•°é‡
                layer_params = layer.count_params()
                if layer_params > 0:
                    print(f"       å‚æ•°æ•°é‡: {layer_params:,}")
                
                print()
            
            # åˆ†æç½‘ç»œæ¶æ„ç±»å‹
            print("ğŸ¯ ç½‘ç»œæ¶æ„åˆ†æ:")
            print("-" * 70)
            layer_types = [layer.__class__.__name__ for layer in best_model.layers]
            
            has_conv = any('Conv' in layer_type for layer_type in layer_types)
            has_lstm = any('LSTM' in layer_type for layer_type in layer_types)
            has_gru = any('GRU' in layer_type for layer_type in layer_types)
            has_rnn = any('RNN' in layer_type or 'LSTM' in layer_type or 'GRU' in layer_type for layer_type in layer_types)
            has_dense = any('Dense' in layer_type for layer_type in layer_types)
            has_dropout = any('Dropout' in layer_type for layer_type in layer_types)
            has_batch_norm = any('BatchNorm' in layer_type for layer_type in layer_types)
            
            architecture_components = []
            if has_conv:
                architecture_components.append("CNNï¼ˆå·ç§¯ç¥ç»ç½‘ç»œï¼‰")
            if has_lstm:
                architecture_components.append("LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰")
            if has_gru:
                architecture_components.append("GRUï¼ˆé—¨æ§å¾ªç¯å•å…ƒï¼‰")
            elif has_rnn and not has_lstm:
                architecture_components.append("RNNï¼ˆå¾ªç¯ç¥ç»ç½‘ç»œï¼‰")
            if has_dense:
                architecture_components.append("å…¨è¿æ¥å±‚")
            
            print(f"æ¶æ„ç»„æˆ: {' + '.join(architecture_components)}")
            
            regularization_techniques = []
            if has_dropout:
                regularization_techniques.append("Dropout")
            if has_batch_norm:
                regularization_techniques.append("æ‰¹å½’ä¸€åŒ–")
            
            if regularization_techniques:
                print(f"æ­£åˆ™åŒ–æŠ€æœ¯: {', '.join(regularization_techniques)}")
            
            # ç»Ÿè®¡å„å±‚ç±»å‹æ•°é‡
            layer_counts = {}
            for layer_type in layer_types:
                layer_counts[layer_type] = layer_counts.get(layer_type, 0) + 1
            
            print(f"\nå„å±‚ç±»å‹ç»Ÿè®¡:")
            for layer_type, count in layer_counts.items():
                print(f"  {layer_type}: {count}å±‚")
                
        else:
            print("âš ï¸ æ— æ³•è·å–è¯¦ç»†æ¶æ„ä¿¡æ¯ - æ¨¡å‹å¯èƒ½å°šæœªè®­ç»ƒå®Œæˆ")
            
    except Exception as e:
        print(f"âŒ æ‰“å°æ¶æ„æ—¶å‡ºé”™: {str(e)}")
        print("è¿™å¯èƒ½æ˜¯ç”±äºæ¨¡å‹å°šæœªå®Œå…¨è®­ç»ƒå®Œæˆ")
    
    print("="*70)

def process_spectrum_data(file_path):
    # 1. åŠ è½½æ•°æ®
    print("æ­£åœ¨åŠ è½½æ•°æ®...")
    data = pd.read_csv(file_path)
    data = data.dropna()
    X = data.iloc[:, 1:-1].values
    y = data.iloc[:, -1].values

    # 2. æ ‡ç­¾ç¼–ç ï¼ˆAutoKeraséœ€è¦ä»0å¼€å§‹çš„æ•´æ•°æ ‡ç­¾ï¼‰
    print("æ­£åœ¨è¿›è¡Œæ ‡ç­¾ç¼–ç ...")
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    print(f"æ ‡ç­¾æ˜ å°„: {dict(zip(le.classes_, range(len(le.classes_))))}")
    print(f"ç±»åˆ«æ•°é‡: {len(le.classes_)}")

    # 3. SGé¢„å¤„ç†
    print("æ­£åœ¨è¿›è¡ŒSGé¢„å¤„ç†...")
    X_sg = savgol_filter(X, window_length=5, polyorder=2, axis=1)

    # 4. æ•°æ®åˆ’åˆ†
    print("æ­£åœ¨åˆ’åˆ†æ•°æ®é›†...")
    X_train, X_test, y_train, y_test = train_test_split(
        X_sg, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded
    )

    # 5. æ•°æ®æ ‡å‡†åŒ–
    print("æ­£åœ¨è¿›è¡Œæ•°æ®æ ‡å‡†åŒ–...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # 6. æ¨¡æ‹Ÿé€€ç«ç‰¹å¾é€‰æ‹©
    print("æ­£åœ¨è¿›è¡Œæ¨¡æ‹Ÿé€€ç«ç‰¹å¾é€‰æ‹©...")
    sa = SA_FeatureSelection(
        n_features=min(80, X.shape[1]//3),  # åŠ¨æ€è°ƒæ•´ç‰¹å¾æ•°
        initial_temperature=50,       # åˆå§‹æ¸©åº¦
        final_temperature=0.01,       # æœ€ç»ˆæ¸©åº¦
        cooling_rate=0.95,           # å†·å´ç‡
        max_iterations=200,          # æœ€å¤§è¿­ä»£æ•°
        cv_folds=3                   # äº¤å‰éªŒè¯æŠ˜æ•°
    )
    
    sa.fit(X_train_scaled, y_train)
    
    X_train_sa = sa.transform(X_train_scaled)
    X_test_sa = sa.transform(X_test_scaled)
    print(f"æ¨¡æ‹Ÿé€€ç«é€‰æ‹©äº† {X_train_sa.shape[1]} ä¸ªç‰¹å¾")
    print(f"ç‰¹å¾é€‰æ‹©ç‡: {X_train_sa.shape[1]}/{X.shape[1]} = {X_train_sa.shape[1]/X.shape[1]*100:.2f}%")

    # 7. è°ƒæ•´æ•°æ®å½¢çŠ¶ä»¥é€‚åº”CNN+RNN (samples, timesteps, features)
    print("æ­£åœ¨è°ƒæ•´æ•°æ®å½¢çŠ¶...")
    # å°†æ•°æ®reshapeä¸º3D: (samples, 1, features) é€‚åˆ1Då·ç§¯å¤„ç†
    X_train_reshaped = X_train_sa.reshape(X_train_sa.shape[0], 1, X_train_sa.shape[1])
    X_test_reshaped = X_test_sa.reshape(X_test_sa.shape[0], 1, X_test_sa.shape[1])
    
    # ç¡®ä¿æ ‡ç­¾ä¸ºæ­£ç¡®çš„å½¢çŠ¶å’Œç±»å‹
    y_train_final = y_train.astype(np.int32)
    y_test_final = y_test.astype(np.int32)
    
    print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train_reshaped.shape}")
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {X_test_reshaped.shape}")
    print(f"è®­ç»ƒæ ‡ç­¾å½¢çŠ¶: {y_train_final.shape}")
    print(f"æµ‹è¯•æ ‡ç­¾å½¢çŠ¶: {y_test_final.shape}")

    # 8. åˆ›å»ºç®€åŒ–çš„AutoKeras CNN+RNNæ¨¡å‹
    print("æ­£åœ¨åˆ›å»ºç®€åŒ–çš„AutoKeras CNN+RNNæ¨¡å‹...")
    
    # ç®€åŒ–çš„æ¶æ„
    input_node = ak.Input()
    output_node = ak.Normalization()(input_node)
    output_node = ak.ConvBlock(num_blocks=1, num_layers=2, dropout=0.1)(output_node)
    output_node = ak.RNNBlock(layer_type='lstm', num_layers=1, bidirectional=False)(output_node)
    output_node = ak.ClassificationHead()(output_node)
    
    autokeras_model = ak.AutoModel(
        inputs=input_node,
        outputs=output_node,
        overwrite=True,
        max_trials=10
    )
    
    print("æ­£åœ¨å¼€å§‹AutoKerasæ¨¡å‹æœç´¢å’Œè®­ç»ƒ...")
    print("è¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    # è®­ç»ƒæ¨¡å‹
    autokeras_model.fit(
        X_train_reshaped, 
        y_train_final,
        validation_split=0.2,
        epochs=800,
        verbose=1
    )
    
    print("AutoKerasæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    
    # æ‰“å°æœç´¢å‡ºæ¥çš„ç½‘ç»œç»“æ„
    print_model_architecture(autokeras_model, "SA + AutoKeras CNN+RNN æœç´¢ç»“æœ")
    
    # 9. æ¨¡å‹è¯„ä¼°
    print("æ­£åœ¨è¿›è¡Œæ¨¡å‹è¯„ä¼°...")
    y_pred = autokeras_model.predict(X_test_reshaped)
    
    # å¤„ç†é¢„æµ‹ç»“æœ
    if len(y_pred.shape) > 1 and y_pred.shape[1] > 1:
        y_pred_final = np.argmax(y_pred, axis=1)
    else:
        y_pred_final = y_pred.flatten().astype(np.int32)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    accuracy = accuracy_score(y_test_final, y_pred_final) * 100
    precision = precision_score(y_test_final, y_pred_final, average='weighted', zero_division=0) * 100
    recall = recall_score(y_test_final, y_pred_final, average='weighted', zero_division=0) * 100
    f1 = f1_score(y_test_final, y_pred_final, average='weighted', zero_division=0) * 100

    print("\n" + "="*60)
    print("     SA + AutoKeras CNN+RNN æ¨¡å‹è¯„ä¼°ç»“æœ")
    print("="*60)
    print(f"å‡†ç¡®ç‡: {accuracy:.2f}%")
    print(f"ç²¾å‡†ç‡: {precision:.2f}%")
    print(f"å¬å›ç‡: {recall:.2f}%")
    print(f"F1å€¼: {f1:.2f}%")
    
    # æ˜¾ç¤ºåˆ†ç±»æŠ¥å‘Š
    from sklearn.metrics import classification_report
    print("\nåˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test_final, y_pred_final, target_names=[str(label) for label in le.classes_]))
    print("="*60)
    
    # æ˜¾ç¤ºç‰¹å¾é€‰æ‹©ä¿¡æ¯
    selected_features = sa.get_selected_features()
    print(f"\næ¨¡æ‹Ÿé€€ç«é€‰æ‹©çš„ç‰¹å¾ç´¢å¼•: {selected_features}")
    print(f"åŸå§‹ç‰¹å¾æ•°é‡: {X.shape[1]}")
    print(f"é€‰æ‹©çš„ç‰¹å¾æ•°é‡: {len(selected_features)}")
    print(f"ç‰¹å¾é€‰æ‹©ç‡: {len(selected_features)/X.shape[1]*100:.2f}%")
    print(f"æ¨¡æ‹Ÿé€€ç«æœ€ä½³é€‚åº”åº¦: {sa.best_fitness:.4f}")
    
    # æ˜¾ç¤ºä¼˜åŒ–è¿‡ç¨‹ä¿¡æ¯
    opt_info = sa.get_optimization_info()
    print(f"\nä¼˜åŒ–è¿‡ç¨‹ä¿¡æ¯:")
    print(f"åˆå§‹é€‚åº”åº¦: {sa.fitness_history[0]:.4f}")
    print(f"æœ€ç»ˆé€‚åº”åº¦: {sa.fitness_history[-1]:.4f}")
    print(f"æœ€ä½³é€‚åº”åº¦: {sa.best_fitness:.4f}")
    print(f"é€‚åº”åº¦æå‡: {sa.best_fitness - sa.fitness_history[0]:.4f}")
    print(f"æ€»ä½“æ¥å—ç‡: {opt_info['final_acceptance_rate']:.2f}%")
    print(f"åˆå§‹æ¸©åº¦: {sa.initial_temperature}")
    print(f"æœ€ç»ˆæ¸©åº¦: {sa.temperature_history[-1]:.6f}")
    
    # æ˜¾ç¤ºæ¨¡å‹æ¶æ„ä¿¡æ¯
    print(f"\næ¨¡å‹æ¶æ„ä¿¡æ¯:")
    print(f"è¾“å…¥å½¢çŠ¶: {X_train_reshaped.shape[1:]}")
    print(f"ç±»åˆ«æ•°é‡: {len(le.classes_)}")
    print(f"æ¶æ„: ç®€åŒ–CNN(ç‰¹å¾æå–) + LSTM(åºåˆ—å»ºæ¨¡) + åˆ†ç±»å¤´")
    print(f"ç‰¹å¾é€‰æ‹©æ–¹æ³•: æ¨¡æ‹Ÿé€€ç«ç®—æ³• (SA)")
    
    # è·å–æœ€ç»ˆæ¨¡å‹
    print("\næ­£åœ¨å¯¼å‡ºæœ€ä½³æ¨¡å‹...")
    final_model = autokeras_model.export_model()
    print("æ¨¡å‹å¯¼å‡ºæˆåŠŸï¼")
    
    return final_model, scaler, sa, le

if __name__ == '__main__':
    # è®¾ç½®éšæœºç§å­ä»¥è·å¾—å¯é‡ç°çš„ç»“æœ
    np.random.seed(42)
    tf.random.set_seed(42)
    random.seed(42)
    
    data_path = r'C:\Users\Administrator\Desktop\ç®¡é“æ·¤æ³¥é¡¹ç›®\å…‰è°±\è¿‘çº¢å¤–æ•°æ®\4.1æ•°æ®-è¿‘çº¢å¤–\65â„ƒ-è¿‡ç­›\65çƒ˜å¹²è¿‡ç­›.csv'
    
    print("æ­£åœ¨å¯åŠ¨åŸºäºæ¨¡æ‹Ÿé€€ç«ç‰¹å¾é€‰æ‹©çš„AutoKeras CNN+RNNåˆ†ç±»æµç¨‹...")
    print("="*70)
    
    result = process_spectrum_data(data_path)
    
    if result[0] is not None:
        print("\næµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
        print("å·²ç”Ÿæˆï¼š")
        print("1. è®­ç»ƒå¥½çš„AutoKeras CNN+RNNæ¨¡å‹")
        print("2. æ•°æ®æ ‡å‡†åŒ–å™¨")
        print("3. æ¨¡æ‹Ÿé€€ç«ç‰¹å¾é€‰æ‹©å™¨")
        print("4. æ ‡ç­¾ç¼–ç å™¨")
    else:
        print("\næµç¨‹æ‰§è¡Œé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚") 